{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_set = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data', \n",
    "                        header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  1      2      3       4       5        6        7        8   \\\n",
       "0      842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010   \n",
       "1      842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690   \n",
       "2    84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740   \n",
       "3    84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140   \n",
       "4    84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800   \n",
       "..        ... ..    ...    ...     ...     ...      ...      ...      ...   \n",
       "564    926424  M  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390   \n",
       "565    926682  M  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400   \n",
       "566    926954  M  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251   \n",
       "567    927241  M  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140   \n",
       "568     92751  B   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000   \n",
       "\n",
       "          9   ...      22     23      24      25       26       27      28  \\\n",
       "0    0.14710  ...  25.380  17.33  184.60  2019.0  0.16220  0.66560  0.7119   \n",
       "1    0.07017  ...  24.990  23.41  158.80  1956.0  0.12380  0.18660  0.2416   \n",
       "2    0.12790  ...  23.570  25.53  152.50  1709.0  0.14440  0.42450  0.4504   \n",
       "3    0.10520  ...  14.910  26.50   98.87   567.7  0.20980  0.86630  0.6869   \n",
       "4    0.10430  ...  22.540  16.67  152.20  1575.0  0.13740  0.20500  0.4000   \n",
       "..       ...  ...     ...    ...     ...     ...      ...      ...     ...   \n",
       "564  0.13890  ...  25.450  26.40  166.10  2027.0  0.14100  0.21130  0.4107   \n",
       "565  0.09791  ...  23.690  38.25  155.00  1731.0  0.11660  0.19220  0.3215   \n",
       "566  0.05302  ...  18.980  34.12  126.70  1124.0  0.11390  0.30940  0.3403   \n",
       "567  0.15200  ...  25.740  39.42  184.60  1821.0  0.16500  0.86810  0.9387   \n",
       "568  0.00000  ...   9.456  30.37   59.16   268.6  0.08996  0.06444  0.0000   \n",
       "\n",
       "         29      30       31  \n",
       "0    0.2654  0.4601  0.11890  \n",
       "1    0.1860  0.2750  0.08902  \n",
       "2    0.2430  0.3613  0.08758  \n",
       "3    0.2575  0.6638  0.17300  \n",
       "4    0.1625  0.2364  0.07678  \n",
       "..      ...     ...      ...  \n",
       "564  0.2216  0.2060  0.07115  \n",
       "565  0.1628  0.2572  0.06637  \n",
       "566  0.1418  0.2218  0.07820  \n",
       "567  0.2650  0.4087  0.12400  \n",
       "568  0.0000  0.2871  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_features = cancer_set.iloc[:,2:]\n",
    "cancer_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        2      3       4       5        6        7        8        9       10  \\\n",
      "0    17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710  0.2419   \n",
      "1    20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690  0.07017  0.1812   \n",
      "2    19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740  0.12790  0.2069   \n",
      "3    11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520  0.2597   \n",
      "4    20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430  0.1809   \n",
      "..     ...    ...     ...     ...      ...      ...      ...      ...     ...   \n",
      "564  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390  0.13890  0.1726   \n",
      "565  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400  0.09791  0.1752   \n",
      "566  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251  0.05302  0.1590   \n",
      "567  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140  0.15200  0.2397   \n",
      "568   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000  0.00000  0.1587   \n",
      "\n",
      "          11  ...      22     23      24      25       26       27      28  \\\n",
      "0    0.07871  ...  25.380  17.33  184.60  2019.0  0.16220  0.66560  0.7119   \n",
      "1    0.05667  ...  24.990  23.41  158.80  1956.0  0.12380  0.18660  0.2416   \n",
      "2    0.05999  ...  23.570  25.53  152.50  1709.0  0.14440  0.42450  0.4504   \n",
      "3    0.09744  ...  14.910  26.50   98.87   567.7  0.20980  0.86630  0.6869   \n",
      "4    0.05883  ...  22.540  16.67  152.20  1575.0  0.13740  0.20500  0.4000   \n",
      "..       ...  ...     ...    ...     ...     ...      ...      ...     ...   \n",
      "564  0.05623  ...  25.450  26.40  166.10  2027.0  0.14100  0.21130  0.4107   \n",
      "565  0.05533  ...  23.690  38.25  155.00  1731.0  0.11660  0.19220  0.3215   \n",
      "566  0.05648  ...  18.980  34.12  126.70  1124.0  0.11390  0.30940  0.3403   \n",
      "567  0.07016  ...  25.740  39.42  184.60  1821.0  0.16500  0.86810  0.9387   \n",
      "568  0.05884  ...   9.456  30.37   59.16   268.6  0.08996  0.06444  0.0000   \n",
      "\n",
      "         29      30       31  \n",
      "0    0.2654  0.4601  0.11890  \n",
      "1    0.1860  0.2750  0.08902  \n",
      "2    0.2430  0.3613  0.08758  \n",
      "3    0.2575  0.6638  0.17300  \n",
      "4    0.1625  0.2364  0.07678  \n",
      "..      ...     ...      ...  \n",
      "564  0.2216  0.2060  0.07115  \n",
      "565  0.1628  0.2572  0.06637  \n",
      "566  0.1418  0.2218  0.07820  \n",
      "567  0.2650  0.4087  0.12400  \n",
      "568  0.0000  0.2871  0.07039  \n",
      "\n",
      "[569 rows x 30 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(cancer_features)\n",
    "print(type(cancer_features))\n",
    "\n",
    "cancer_features = cancer_features.values\n",
    "print(cancer_features)\n",
    "print(type(cancer_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_features_names = ['mean radius', \n",
    "'mean texture', 'mean perimeter', \n",
    "'mean area', 'mean smoothness', \n",
    "'mean compactness', 'mean concavity',\n",
    "'mean concave points', 'mean symmetry',\n",
    "'mean fractal dimension','radius error',\n",
    "'texture error','perimeter error',\n",
    "'area error', 'smoothness error',\n",
    "'compactness error','concavity error',\n",
    "'concave points error','symmetry error',\n",
    "'fractal dimension error','worst radius',\n",
    "'worst texture', 'worst perimeter', \n",
    "'worst area','worst smoothness', \n",
    "'worst compactness', 'worst concavity',\n",
    "'worst concave points','worst symmetry',\n",
    "'worst fractal dimension']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
      "<class 'numpy.ndarray'>\n",
      "(569,)\n"
     ]
    }
   ],
   "source": [
    "cancer_target = cancer_set.iloc[:,1]\n",
    "\n",
    "# Replacing 'M' with 0 and 'B' with 1\n",
    "cancer_target = cancer_target.replace(['M','B'],[0,1])\n",
    "\n",
    "# Converting to numpy array\n",
    "cancer_target = cancer_target.values\n",
    "\n",
    "print(cancer_target)\n",
    "print(type(cancer_target))\n",
    "print(cancer_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "import sklearn.preprocessing as preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.16286735e-15 -6.53060890e-15 -7.07889127e-16 -8.79983452e-16\n",
      "  6.13217737e-15 -1.12036918e-15 -4.42138027e-16  9.73249991e-16\n",
      " -1.97167024e-15 -1.45363120e-15 -9.07641468e-16 -8.85349205e-16\n",
      "  1.77367396e-15 -8.29155139e-16 -7.54180940e-16 -3.92187747e-16\n",
      "  7.91789988e-16 -2.73946068e-16 -3.10823423e-16 -3.36676596e-16\n",
      " -2.33322442e-15  1.76367415e-15 -1.19802625e-15  5.04966114e-16\n",
      " -5.21317026e-15 -2.17478837e-15  6.85645643e-16 -1.41265636e-16\n",
      " -2.28956670e-15  2.57517109e-15]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "standardizer = preprocessing.StandardScaler()\n",
    "standardizer = standardizer.fit(cancer.data)\n",
    "breast_cancer_standardized = standardizer.transform(cancer.data)\n",
    "\n",
    "print(breast_cancer_standardized.mean(axis = 0))\n",
    "print(breast_cancer_standardized.std(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.21037437, 0.22658099, 5.45988529, ..., 9.12027491, 5.98462448,\n",
       "        4.18863964],\n",
       "       [6.43144493, 2.72573554, 6.15783291, ..., 6.39175258, 2.33589592,\n",
       "        2.22878132],\n",
       "       [6.01495575, 3.90260399, 5.95743211, ..., 8.35051546, 4.03705894,\n",
       "        2.13433032],\n",
       "       ...,\n",
       "       [4.55251077, 6.21237741, 4.45788128, ..., 4.87285223, 1.28720678,\n",
       "        1.51908697],\n",
       "       [6.44564343, 6.63510315, 6.65537972, ..., 9.10652921, 4.97141731,\n",
       "        4.52315361],\n",
       "       [0.36868759, 5.01521813, 0.28539838, ..., 0.        , 2.57441356,\n",
       "        1.00682146]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0,10)).fit(cancer.data)\n",
    "breast_cancer_minmaxscaled10 = min_max_scaler.transform(cancer.data)\n",
    "breast_cancer_minmaxscaled10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52103744, 0.0226581 , 0.54598853, ..., 0.91202749, 0.59846245,\n",
       "        0.41886396],\n",
       "       [0.64314449, 0.27257355, 0.61578329, ..., 0.63917526, 0.23358959,\n",
       "        0.22287813],\n",
       "       [0.60149557, 0.3902604 , 0.59574321, ..., 0.83505155, 0.40370589,\n",
       "        0.21343303],\n",
       "       ...,\n",
       "       [0.45525108, 0.62123774, 0.44578813, ..., 0.48728522, 0.12872068,\n",
       "        0.1519087 ],\n",
       "       [0.64456434, 0.66351031, 0.66553797, ..., 0.91065292, 0.49714173,\n",
       "        0.45231536],\n",
       "       [0.03686876, 0.50152181, 0.02853984, ..., 0.        , 0.25744136,\n",
       "        0.10068215]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler().fit(cancer.data)\n",
    "breast_cancer_minmaxscaled = min_max_scaler.transform(cancer.data)\n",
    "breast_cancer_minmaxscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63998577, 0.26425662, 0.65145889, ..., 0.91202749, 0.69313046,\n",
       "        0.57301205],\n",
       "       [0.73176805, 0.45239308, 0.70503979, ..., 0.63917526, 0.41428141,\n",
       "        0.42901205],\n",
       "       [0.70046247, 0.54098778, 0.68965517, ..., 0.83505155, 0.54429045,\n",
       "        0.42207229],\n",
       "       ...,\n",
       "       [0.59053718, 0.71486762, 0.57453581, ..., 0.48728522, 0.33413679,\n",
       "        0.37686747],\n",
       "       [0.73283529, 0.74669043, 0.74323607, ..., 0.91065292, 0.6156975 ,\n",
       "        0.59759036],\n",
       "       [0.27605834, 0.62474542, 0.25421751, ..., 0.        , 0.43250979,\n",
       "        0.33922892]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_abs_scaler = preprocessing.MaxAbsScaler().fit(cancer.data)\n",
    "breast_cancer_maxabsscaled = max_abs_scaler.transform(cancer.data)\n",
    "breast_cancer_maxabsscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.04461573e-03, 2.91067878e-03, 3.44346198e-02, ...,\n",
       "        7.44214015e-05, 1.29017660e-04, 3.33410122e-05],\n",
       "       [5.49864230e-03, 4.75016401e-03, 3.55259874e-02, ...,\n",
       "        4.97203436e-05, 7.35112606e-05, 2.37962634e-05],\n",
       "       [5.81273050e-03, 6.27326171e-03, 3.83776011e-02, ...,\n",
       "        7.17365928e-05, 1.06660210e-04, 2.58546946e-05],\n",
       "       ...,\n",
       "       [7.00344278e-03, 1.18467875e-02, 4.56911357e-02, ...,\n",
       "        5.98245895e-05, 9.35761210e-05, 3.29921220e-05],\n",
       "       [5.68390968e-03, 8.09267334e-03, 3.86561042e-02, ...,\n",
       "        7.31182555e-05, 1.12767664e-04, 3.42138252e-05],\n",
       "       [1.18802525e-02, 3.75697675e-02, 7.33636209e-02, ...,\n",
       "        0.00000000e+00, 4.39538722e-04, 1.07764300e-04]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer = preprocessing.Normalizer(norm='l1').fit(cancer.data)\n",
    "breast_cancer_normalized = normalizer.transform(cancer.data)\n",
    "breast_cancer_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarizer = preprocessing.Binarizer(threshold=3.0).fit(cancer.data)\n",
    "breast_cancer_binarized = binarizer.transform(cancer.data)\n",
    "breast_cancer_binarized[:5,:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]]\n",
      "[[0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "onehotencoder = preprocessing.OneHotEncoder()\n",
    "onehotencoder = onehotencoder.fit([[1], [1], [1], [2], [2], [1]])\n",
    "\n",
    "# Transforming category values 1 and 2 to one-hot vectors\n",
    "print(onehotencoder.transform([[1]]).toarray())\n",
    "print(onehotencoder.transform([[2]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.preprocessing' has no attribute 'Imputer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-8fd2f605cf36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimputer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImputer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'NaN'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimputer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbreast_cancer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbreast_cancer_imputed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbreast_cancer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbreast_cancer_imputed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'sklearn.preprocessing' has no attribute 'Imputer'"
     ]
    }
   ],
   "source": [
    "imputer = preprocessing.Imputer(missing_values='NaN', strategy='mean')\n",
    "\n",
    "imputer = imputer.fit(breast_cancer.data)\n",
    "breast_cancer_imputed = imputer.transform(breast_cancer.data)\n",
    "breast_cancer_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "imp = SimpleImputer(missing_values=np.NaN, strategy=\"mean\" ).fit(cancer.data)\n",
    "breast_cancer_imputed = imp.transform(cancer.data)\n",
    "breast_cancer_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelencoder = preprocessing.LabelEncoder().fit(cancer.target_names)\n",
    "bc_labelencoded = labelencoder.transform(cancer.target_names)\n",
    "bc_labelencoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['malignant', 'benign', 'malignant', 'benign']\n",
    "labelencoder = preprocessing.LabelEncoder()\n",
    "labelencoder = labelencoder.fit(labels)\n",
    "bc_labelencoded = labelencoder.transform(cancer.target_names)\n",
    "bc_labelencoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75140029 0.40517418 0.45478362 0.14107142]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as datasets\n",
    "import sklearn.preprocessing as preprocessing\n",
    "iris = datasets.load_iris()\n",
    "normalizer = preprocessing.Normalizer().fit(iris.data)\n",
    "iris_normalized = normalizer.transform(iris.data)\n",
    "print(iris_normalized.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as datasets\n",
    "import sklearn.preprocessing as preprocessing\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "onehotencoder = preprocessing.OneHotEncoder().fit(iris.target.reshape(-1,1))\n",
    "iris_target_onehot = onehotencoder.transform(iris.target.reshape(-1,1))\n",
    "print(iris_target_onehot.toarray()[[0,50,100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.262 2.872 4.906 1.676]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as datasets\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "iris.data[:50] = np.NaN\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.NaN, strategy=\"mean\" ).fit(iris.data)\n",
    "iris_imputed = imp.transform(iris.data)\n",
    "print(iris_imputed.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1)\n"
     ]
    }
   ],
   "source": [
    "x = [[7.8], [1.3], [4.5], [0.9]]\n",
    "print(preprocessing.Binarizer().fit(x).transform(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Data : 0.9460093896713615\n",
      "Accuracy of Test Data : 0.9300699300699301\n"
     ]
    }
   ],
   "source": [
    "# importing required modules and loading cancer dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "\n",
    "# Building a Model of KNN classifier\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(cancer.data, cancer.target,\n",
    "                                                    stratify = cancer.target,\n",
    "                                                    random_state = 42)\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_classifier = knn_classifier.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "# Determining Accuracy of the Model\n",
    "print('Accuracy of Train Data :', knn_classifier.score(X_train,Y_train))\n",
    "print('Accuracy of Test Data :', knn_classifier.score(X_test,Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 4)\n",
      "(38, 4)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(iris.data, iris.target,\n",
    "                                                    stratify = iris.target, \n",
    "                                                    random_state = 30)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9821428571428571\n",
      "0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(iris.data, iris.target,\n",
    "                                                    stratify = iris.target, \n",
    "                                                    random_state = 30)\n",
    "\n",
    "knn_classifier = KNeighborsClassifier().fit(X_train,Y_train)\n",
    "print(knn_classifier.score(X_train,Y_train))\n",
    "print(knn_classifier.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(iris.data, iris.target,\n",
    "                                                    stratify = iris.target, \n",
    "                                                    random_state = 30)\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3).fit(X_train,Y_train)\n",
    "accuracy0 = knn_classifier.score(X_test,Y_test)\n",
    "n_neighbors = 3\n",
    "for i in range(4,11):\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=i).fit(X_train,Y_train)\n",
    "    accuracy1 = knn_classifier.score(X_test,Y_test)\n",
    "    if accuracy1 > accuracy0:\n",
    "        n_neighbors = i\n",
    "    accuracy0 = accuracy1\n",
    "print(n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Data : 1.0\n",
      "Accuracy of Test Data : 0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "# Decision Trees\n",
    "\n",
    "# importing required modules, load cancer dataset, and create train and test data sets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.datasets as datasets\n",
    "\n",
    "cancer = datasets.load_breast_cancer()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( cancer.data, cancer.target,\n",
    "                                                   stratify = cancer.target,\n",
    "                                                   random_state = 30)\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "dt_classifier = dt_classifier.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "# Determining Accuracy of the Model\n",
    "print('Accuracy of Train Data :', dt_classifier.score(X_train,Y_train))\n",
    "print('Accuracy of Test Data :', dt_classifier.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Data : 0.9647887323943662\n",
      "Accuracy of Test Data : 0.9020979020979021\n"
     ]
    }
   ],
   "source": [
    "# Fine Tuning the Above Model\n",
    "dt_classifier = DecisionTreeClassifier(max_depth= 2)\n",
    "dt_classifier = dt_classifier.fit(X_train, Y_train)\n",
    "\n",
    "print('Accuracy of Train Data :', dt_classifier.score(X_train,Y_train))\n",
    "print('Accuracy of Test Data :', dt_classifier.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 13)\n",
      "(127, 13)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "np.random.seed(100)\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( boston.data, boston.target, random_state = 30)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.7883979988271616\n",
      "[32.9 23.9]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "np.random.seed(100)\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( boston.data, boston.target, random_state = 30)\n",
    "dt_reg = DecisionTreeRegressor()\n",
    "dt_reg = dt_reg.fit(X_train, Y_train)\n",
    "\n",
    "print(dt_reg.score(X_train, Y_train))\n",
    "print(dt_reg.score(X_test, Y_test))\n",
    "print(dt_reg.predict(X_test[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6189051959855576\n",
      "0.699781997031047\n",
      "0.737701724177952\n",
      "0.7824055448239499\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "np.random.seed(100)\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( boston.data, boston.target)#, random_state = 30)\n",
    "\n",
    "dt_reg = DecisionTreeRegressor(max_depth=2).fit(X_train, Y_train)\n",
    "accuracy0 = dt_reg.score(X_test, Y_test)\n",
    "depth = 2\n",
    "print(accuracy0)\n",
    "for i in range(3,6):\n",
    "    dt_reg = DecisionTreeRegressor(max_depth=i).fit(X_train, Y_train)\n",
    "    accuracy1 = dt_reg.score(X_test, Y_test)\n",
    "    print(accuracy1)\n",
    "    if accuracy1 > accuracy0:\n",
    "        depth = i\n",
    "#     print(accuracy1)\n",
    "#     print(max_depth)\n",
    "    \n",
    "    accuracy0 = accuracy1\n",
    "print(depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Data : 1.0\n",
      "Accuracy of Test Data : 0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "# Demo of Random Forest Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( cancer.data, cancer.target,\n",
    "                                                   stratify = cancer.target,\n",
    "                                                   random_state = 42)\n",
    "\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier = rf_classifier.fit(X_train, Y_train)\n",
    "print('Accuracy of Train Data :', rf_classifier.score(X_train,Y_train))\n",
    "print('Accuracy of Test Data :', rf_classifier.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Data : 1.0\n",
      "Accuracy of Test Data : 0.965034965034965\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( cancer.data, cancer.target,\n",
    "                                                   stratify = cancer.target)\n",
    "\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier = rf_classifier.fit(X_train, Y_train) \n",
    "\n",
    "print('Accuracy of Train Data :', rf_classifier.score(X_train,Y_train))\n",
    "print('Accuracy of Test Data :', rf_classifier.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 13)\n",
      "(127, 13)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "np.random.seed(100)\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( boston.data, boston.target, random_state = 30)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.887575241889432\n",
      "0.8413867238252251\n",
      "[21.03543307  8.8047619 ]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "np.random.seed(100)\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( boston.data, boston.target, random_state = 30)\n",
    "rf_reg = RandomForestRegressor()\n",
    "rf_reg = rf_reg.fit(X_train, Y_train)\n",
    "\n",
    "print(rf_reg.score(X_train, Y_train))\n",
    "print(rf_reg.score(X_test, Y_test))\n",
    "print(rf_reg.predict(X_test[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 100)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "np.random.seed(100)\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( boston.data, boston.target, random_state = 30)\n",
    "\n",
    "rf_reg = RandomForestRegressor(max_depth=3,n_estimators=50)\n",
    "rf_reg = rf_reg.fit(X_train, Y_train)\n",
    "accuracy0 = rf_reg.score(X_test, Y_test)\n",
    "max_depth = 3\n",
    "n_estimators = 50\n",
    "\n",
    "for i in range(3,6):\n",
    "    for j in [50,100,200]:\n",
    "        rf_reg = RandomForestRegressor(max_depth=i,n_estimators=j)\n",
    "        rf_reg = rf_reg.fit(X_train, Y_train)\n",
    "        accuracy1 = rf_reg.score(X_test, Y_test)\n",
    "        \n",
    "        if accuracy1 > accuracy0:\n",
    "            max_depth = i\n",
    "            n_estimators = j\n",
    "        accuracy0 = accuracy1\n",
    "\n",
    "print((max_depth, n_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Data : 0.9225352112676056\n",
      "Accuracy of Test Data : 0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "# Demo of Support Vector Classification\n",
    "# An example of creating an SVM classifier is shown below.\n",
    "\n",
    "# The shown model overfits the training data.\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "cancer = datasets.load_breast_cancer()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( cancer.data, cancer.target,\n",
    "                                                   stratify = cancer.target)\n",
    "\n",
    "svm_classifier = SVC()\n",
    "svm_classifier = svm_classifier.fit(X_train, Y_train)\n",
    "print('Accuracy of Train Data :', svm_classifier.score(X_train,Y_train))\n",
    "print('Accuracy of Test Data :', svm_classifier.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Data : 0.9178403755868545\n",
      "Accuracy of Test Data : 0.9230769230769231\n",
      "\n",
      "Accuracy of Train Data : 0.9859154929577465\n",
      "Accuracy of Test Data : 0.986013986013986\n"
     ]
    }
   ],
   "source": [
    "# Improving Accuracy Using Scaled Data\n",
    "# In the following example, scaled input data is used to improve the accuracy of SVM classifier.\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( cancer.data, cancer.target,\n",
    "                                                   stratify = cancer.target)\n",
    "\n",
    "svm_classifier = SVC()\n",
    "svm_classifier = svm_classifier.fit(X_train, Y_train)\n",
    "print('Accuracy of Train Data :', svm_classifier.score(X_train,Y_train))\n",
    "print('Accuracy of Test Data :', svm_classifier.score(X_test,Y_test))\n",
    "\n",
    "print()\n",
    "\n",
    "standardizer = StandardScaler()\n",
    "standardizer = standardizer.fit(cancer.data)\n",
    "cancer_standardized  = standardizer.transform(cancer.data)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( cancer_standardized, cancer.target,\n",
    "                                                   stratify = cancer.target)\n",
    "svm_classifier = SVC()\n",
    "svm_classifier = svm_classifier.fit(X_train, Y_train)\n",
    "print('Accuracy of Train Data :', svm_classifier.score(X_train,Y_train))\n",
    "print('Accuracy of Test Data :', svm_classifier.score(X_test,Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        53\n",
      "           1       0.99      0.99      0.99        90\n",
      "\n",
      "    accuracy                           0.99       143\n",
      "   macro avg       0.99      0.99      0.99       143\n",
      "weighted avg       0.99      0.99      0.99       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Viewing the Classification Report\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "Y_pred = svm_classifier.predict(X_test)\n",
    "print('Classification report : \\n',metrics.classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1347, 64)\n",
      "(450, 64)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(digits.data, digits.target, random_state=30, stratify = digits.target)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9822222222222222\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "    \n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(digits.data, digits.target, random_state=30, stratify = digits.target)\n",
    "\n",
    "svm_clf = SVC()\n",
    "svm_clf = svm_clf.fit(X_train, Y_train)\n",
    "\n",
    "print(svm_clf.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "digits = datasets.load_digits()\n",
    "\n",
    "standardizer = StandardScaler().fit(digits.data)\n",
    "digits_standardized = standardizer.transform(digits.data)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(digits_standardized, digits.target, random_state=30, stratify = digits.target)\n",
    "\n",
    "svm_clf2 = SVC()\n",
    "svm_clf2 = svm_clf2.fit(X_train, Y_train)\n",
    "\n",
    "print(svm_clf2.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demo of KMeans\n",
    "# An example of performing KMeans clustering is shown below\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans_cluster = KMeans(n_clusters=2)\n",
    "kmeans_cluster = kmeans_cluster.fit(X_train) \n",
    "\n",
    "kmeans_cluster.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8590276495020881\n",
      "0.5149173437707478\n",
      "0.6438805595172867\n",
      "0.5268896419625755\n"
     ]
    }
   ],
   "source": [
    "# Evaluation with scikit-learn\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.homogeneity_score(kmeans_cluster.predict(X_test), Y_test))\n",
    "print(metrics.completeness_score(kmeans_cluster.predict(X_test), Y_test))\n",
    "print(metrics.v_measure_score(kmeans_cluster.predict(X_test), Y_test))\n",
    "print(metrics.adjusted_rand_score(kmeans_cluster.predict(X_test), Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7649861514489815\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "km_cls = KMeans(n_clusters=3)\n",
    "km_cls = km_cls.fit(iris.data)\n",
    "\n",
    "print(metrics.homogeneity_score(km_cls.predict(iris.data),iris.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7795958005591144\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as datasets\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn import metrics\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "agg_cls = AgglomerativeClustering(n_clusters=3)\n",
    "agg_cls = agg_cls.fit(iris.data)\n",
    "\n",
    "print(metrics.homogeneity_score(agg_cls.labels_,iris.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5278221404408368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anurag\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:146: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 0.25 which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn((\"'random_state' has been introduced in 0.23. \"\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as datasets\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn import metrics\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "af_cls = AffinityPropagation()\n",
    "af_cls = af_cls.fit(iris.data)\n",
    "\n",
    "print(metrics.homogeneity_score(af_cls.labels_,iris.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing as preprocessing\n",
    "\n",
    "x = [[7.8], [1.3], [4.5], [0.9]]\n",
    "print(preprocessing.Binarizer().fit(x).transform(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 3 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "regions = ['HYD', 'CHN', 'MUM', 'HYD', 'KOL', 'CHN']\n",
    "print(preprocessing.LabelEncoder().fit(regions).transform(regions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
